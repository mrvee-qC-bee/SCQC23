{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430c361a",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "For SCQC Summer School of Quantum Computing 2023 <br>\n",
    "Yuri Kobayashi (June 13, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347aba87",
   "metadata": {},
   "source": [
    "In machine learning, support vector machines are supervised learning models with associated learning algorithms that analyze data for classification and regresion analysis.\n",
    "\n",
    "In this tutorial, we will learn how to prepare, encode, train, and then clasify data using example data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bdc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# for plotting results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Scikit-learn(QML library for Python)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split # for splitting test data\n",
    "from sklearn.svm import SVC # SVM Classification\n",
    "from sklearn.decomposition import PCA # Principal component analysis\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # for standardization, normalization scale conversion\n",
    "\n",
    "# Import Qiskit\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b54454",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Here we handle a subset of 0s and 1s from the handwritten digital image dataset (MNIST dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2328bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads two classes of data (0 and 1) from a numeric data set\n",
    "digits = datasets.load_digits(n_class=2)   \n",
    "\n",
    "# Plot the first 100 images loaded\n",
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15), subplot_kw={'xticks':[], 'yticks':[]}, gridspec_kw=dict(hspace=0.5, wspace=0.5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title(digits.target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c3548",
   "metadata": {},
   "source": [
    "This data set contains a total of 360 data points. Each data point is an 8 x 8 numbered image, in an array, with each element being an integer from 0 (white) to 16 (black). As with classical classification algorithms, the dataset must be divided and normalized into training (100) and testing (20) samples. To use this dataset for the quantum classification algorithm, the range is scaled between -1 and 1 and the dimension is reduced to the number of qubits used (4 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a33fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "     digits.data, digits.target, test_size=0.2, random_state=22)\n",
    "\n",
    "# Delete dimension\n",
    "n_dim = 4\n",
    "pca = PCA(n_components=n_dim).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# Standardize\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Normalize\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Select 100 for training and 20 for testing\n",
    "train_size = 100\n",
    "sample_train = sample_train[:train_size]\n",
    "labels_train = labels_train[:train_size]\n",
    "\n",
    "test_size = 20\n",
    "sample_test = sample_test[:test_size]\n",
    "labels_test = labels_test[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display each of the first data\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca145c8",
   "metadata": {},
   "source": [
    "## Data encoding\n",
    "\n",
    "This classical data is then encoded into the quantum state space using a quantum feature map (ZZFeatureMap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e62322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZZFeatureMap with 4 features and depth (number of iterations)1\n",
    "zz_map = ZZFeatureMap(feature_dimension=4, reps=1, entanglement='linear', insert_barriers=True)\n",
    "zz_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df71b1",
   "metadata": {},
   "source": [
    "## Quantum Kernel Computation\n",
    "\n",
    "The quantum feature map $\\phi(\\vec{x})$ can be used to create a quantum kernel $k(\\vec{x}_i,\\vec{x}_j)= \\phi(\\vec{x}_j)^\\dagger\\phi(\\vec{x}_i)$. This can be thought of a measure of how similar the two vectors are. The larger the closer the two $\\vec{x}_i$ and $\\vec{x}_j$ are.\n",
    "\n",
    "In this case, we will use ZZFeatureMap to calculate the quantum kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_kernel = QuantumKernel(feature_map=zz_map, quantum_instance=Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c073d",
   "metadata": {},
   "source": [
    "For the 0th and 1st data in the training data, we create a quantum circuit to compute the quantum kernel and actually compute the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095aaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train[0])\n",
    "print(sample_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_circuit = zz_kernel.construct_circuit(sample_train[0], sample_train[1])\n",
    "zz_circuit.decompose().decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dc775",
   "metadata": {},
   "source": [
    "The parameter values for each rotation gate are a bit hard to read, but you can see that the circuit is symmetrical. The left half of the circuit is coded for the training data sample_train[0] and the right half for the training data sample_train[1].\n",
    "\n",
    "As an example, measure the above quantum kernel and calculate the elements of the kernel matrix (for the zero and first data of the training data) as a percentage of the counts of zero states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "job = execute(zz_circuit, backend, shots=8192, \n",
    "              seed_simulator=1024, seed_transpiler=1024)\n",
    "counts = job.result().get_counts(zz_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ea635",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['0000']/sum(counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b5e91",
   "metadata": {},
   "source": [
    "This process is repeated for each pair of training data samples to fill the training kernel matrix, and then repeated between training and test data samples to fill the test kernel matrix. Note that since each matrix is symmetric, only half of the elements are computed to reduce computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf2fb0",
   "metadata": {},
   "source": [
    "Calculate the kernel matrices for the training and test data using the QuantumKernel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6652797",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = zz_kernel.evaluate(x_vec=sample_train)\n",
    "matrix_test = zz_kernel.evaluate(x_vec=sample_test, y_vec=sample_train)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"testing kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54584f70",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will train it using the `svc` algorithm of the classical SVM classifier `scikit-learn` and see the learning rate on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9014117",
   "metadata": {},
   "outputs": [],
   "source": [
    "zzpc_svc = SVC(kernel='precomputed')\n",
    "zzpc_svc.fit(matrix_train, labels_train)    # Train\n",
    "zzpc_score = zzpc_svc.score(matrix_test, labels_test)    # Determine the percentage of correct answers\n",
    "\n",
    "print(f'Kernel classification test score: {zzpc_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ea99e",
   "metadata": {},
   "source": [
    "We can see that we have classified the test data points almost correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480af64b",
   "metadata": {},
   "source": [
    "# Classification of Clothing Image Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cc976",
   "metadata": {},
   "source": [
    "The data we deal with here is a subset of the clothing image dataset [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md), which is a variant of the MNIST dataset which is a subset of the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf47bb9",
   "metadata": {},
   "source": [
    "\n",
    "<center><div><img src=\"fashion-mnist-sprite.png\" width=\"640\" /></div></center>\n",
    "\n",
    "Image source:[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44828aa1",
   "metadata": {},
   "source": [
    "Let's classify images for the following labels\n",
    "\n",
    "- label 2: pullovers\n",
    "- label 3: dresses\n",
    "\n",
    "First, load the dataset and display one image per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import cm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import Scikit-learn(QML library for Python)\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import Qiskit\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_PATH = 'fashion.npz'\n",
    "data = np.load(DATA_PATH)\n",
    "\n",
    "sample_train = data['sample_train']\n",
    "labels_train = data['labels_train']\n",
    "sample_test = data['sample_test']\n",
    "\n",
    "# Splitting the dataset\n",
    "sample_train, sample_test, labels_train, labels_test = train_test_split(\n",
    "    sample_train, labels_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Show data\n",
    "fig = plt.figure()\n",
    "LABELS = [2,3]\n",
    "num_labels = len(LABELS)\n",
    "for i in range(num_labels):\n",
    "    ax = fig.add_subplot(2, num_labels, i+1)\n",
    "    img = sample_train[labels_train==LABELS[i]][0].reshape((28, 28))\n",
    "    ax.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a8b51",
   "metadata": {},
   "source": [
    "Next, let's preprocess the following datasets\n",
    "\n",
    "- Standardization\n",
    "- Dimensionality Compression by Principal Component Analysis (PCA)\n",
    "- Normalization\n",
    "\n",
    "The number of dimensions can be changed by changing N_DIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dimension\n",
    "N_DIM = 4\n",
    "pca = PCA(n_components=N_DIM).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# standardize\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# normalize\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display each of the first data\n",
    "print(sample_train[0], labels_train[0])\n",
    "print(sample_test[0], labels_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b02ee",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "For this clothing image data, we compute a kernel matrix using a feature map (ZZFeatureMap) and a quantum kernel (QuantumKernel class) and train it using a classical SVM. Check the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_map = # Write your code here!\n",
    "zz_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68587ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_kernel = # Write your code here!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b003d46d",
   "metadata": {},
   "source": [
    "For the 0th and 1st data in the training data, we create a quantum circuit to compute the quantum kernel and actually compute the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d874b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train[0])\n",
    "print(sample_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_circuit = zz_kernel.construct_circuit(sample_train[0], sample_train[1])\n",
    "zz_circuit.decompose().decompose().draw(output='mpl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "job = execute(zz_circuit, backend, shots=8192, \n",
    "              seed_simulator=1024, seed_transpiler=1024)\n",
    "counts = job.result().get_counts(zz_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['0000']/sum(counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b4baa",
   "metadata": {},
   "source": [
    "Calculate the kernel matrices for the training and test data using the QuantumKernel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = # Write your code here!\n",
    "matrix_test = # Write your code here!\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train),\n",
    "              interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test),\n",
    "              interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"testing kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88850a5",
   "metadata": {},
   "source": [
    "We will train it using the `svc` algorithm of the classical SVM classifier `scikit-learn` and see the learning rate on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa52183",
   "metadata": {},
   "outputs": [],
   "source": [
    "zzpc_svc = # Write your code here!\n",
    "zzpc_svc.fit(matrix_train, labels_train)\n",
    "zzpc_score = # Write your code here!\n",
    "\n",
    "print(f'Kernel classification test score: {zzpc_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f551683",
   "metadata": {},
   "source": [
    "How was your classification test score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30da39f",
   "metadata": {},
   "source": [
    "Congratultaions! You were able to successfully create a classifier that distinguishes overalls from dresses! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
